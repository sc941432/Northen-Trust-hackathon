{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f7ce9f67-3cd6-4fa3-b818-0c77a2b191f7",
   "metadata": {},
   "source": [
    "## **To Merge the Provided Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48e257d8-509a-45b3-b1c6-78279cc15f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "file_paths = glob.glob('Exchange_Rate_Report_*.csv')\n",
    "\n",
    "processed_dfs = []\n",
    "\n",
    "for file_path in file_paths:\n",
    "   \n",
    "    exchange_rate_df = pd.read_csv(file_path)\n",
    "\n",
    "    # Step 1: Convert the \"Date\" column to datetime format, and drop rows where the conversion failed\n",
    "    exchange_rate_df['Date'] = pd.to_datetime(exchange_rate_df['Date'], format='%d-%b-%y', errors='coerce')\n",
    "    exchange_rate_df = exchange_rate_df.dropna(subset=['Date'])  # Drop rows where 'Date' is NaT\n",
    "\n",
    "    # Step 2: Create a full date range from January 1st to the maximum date in the dataset\n",
    "    full_date_range = pd.date_range(start=f'{exchange_rate_df[\"Date\"].min().year}-01-01', end=exchange_rate_df['Date'].max())\n",
    "\n",
    "    # Step 3: Reindex the DataFrame to include all dates in the range\n",
    "    exchange_rate_df.set_index('Date', inplace=True)\n",
    "    reindexed_df = exchange_rate_df.reindex(full_date_range)\n",
    "\n",
    "    # Step 4: Backward fill for missing values at the beginning, then forward fill for the rest\n",
    "    filled_df = reindexed_df.bfill().ffill()\n",
    "\n",
    "    # Step 5: Fill any remaining missing values in the dataset using the mean method\n",
    "    filled_df = filled_df.fillna(filled_df.mean())\n",
    "\n",
    "    # Append the cleaned and filled DataFrame to the list\n",
    "    processed_dfs.append(filled_df)\n",
    "\n",
    "\n",
    "final_df = pd.concat(processed_dfs)\n",
    "final_df.to_csv('Merged_Exchange_Rate_2013_2022.csv')\n",
    "\n",
    "print(\"All CSV files processed, missing values handled, and merged into 'Merged_Exchange_Rate_2013_2022.csv'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d0961e6-cd30-4752-ba24-8323609d63c2",
   "metadata": {},
   "source": [
    "## **To Merge the IMF Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33847560-43cc-44d8-b83a-7e14fa31c5cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "\n",
    "# Specify the folder path where your files are located\n",
    "folder_path = 'path_to_your_csv_folder'  # Update this path with the actual folder path\n",
    "\n",
    "# Change directory to the folder containing the CSV files\n",
    "os.chdir(folder_path)\n",
    "\n",
    "# Use glob to find all CSV files that end with '_transposed.csv'\n",
    "file_paths = glob.glob('*_transposed.csv')\n",
    "print(\"CSV files found:\", file_paths)  # This will print the list of found files\n",
    "\n",
    "# Check if any files were found\n",
    "if not file_paths:\n",
    "    print(\"No files matching the pattern were found.\")\n",
    "else:\n",
    "    processed_dfs = []\n",
    "    for file_path in file_paths:\n",
    "        try:\n",
    "            # Read CSV\n",
    "            df = pd.read_csv(file_path)\n",
    "            print(f\"Processing file: {file_path}\")\n",
    "            print(df.head())  # Display the first few rows\n",
    "            \n",
    "            # Process the DataFrame (example: forward fill missing values)\n",
    "            filled_df = df.fillna(method='ffill')  # Adjust your processing logic as needed\n",
    "            processed_dfs.append(filled_df)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {file_path}: {e}\")\n",
    "\n",
    "    # Concatenate all DataFrames if they exist\n",
    "    if processed_dfs:\n",
    "        final_df = pd.concat(processed_dfs)\n",
    "        final_df.to_csv('Merged_Exchange_Rate_2013_2022.csv', index=False)  # Save the merged CSV\n",
    "        print(\"All CSV files processed and merged into 'Merged_Exchange_Rate_2013_2022.csv'.\")\n",
    "    else:\n",
    "        print(\"No valid DataFrames to concatenate.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faa5b01f-44a5-4d4f-bab2-903c2bc2b877",
   "metadata": {},
   "source": [
    "## **Final Formating of Both Files Before Merging**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53677fa9-b7d9-4f98-bf4d-5f957afd6530",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file into a pandas DataFrame\n",
    "df = pd.read_csv('path_to_your_csv_file/Converted_Exchange_Rate.csv')  # Update with the correct path\n",
    "\n",
    "# Convert 'Unnamed: 0' column to datetime, and format it as 'YYYY-MM-DD'\n",
    "#df['Unnamed: 0'] = pd.to_datetime(df['Unnamed: 0'], format='%B %d, %Y').dt.strftime('%Y-%m-%d')\n",
    "\n",
    "# Rename the column to 'Date'\n",
    "df.rename(columns={'Unnamed: 0': 'Date'}, inplace=True)\n",
    "df.columns = df.columns.str.strip().str.replace(r'\\s+', ' ', regex=True)\n",
    "\n",
    "# Extract the 'Date' column\n",
    "date_column = df['Date']\n",
    "\n",
    "# Sort all columns except 'Date' alphabetically\n",
    "sorted_columns = sorted(df.columns.difference(['Date']))\n",
    "\n",
    "# Apply column-wise interpolation (numeric columns only)\n",
    "df[sorted_columns] = df[sorted_columns].interpolate(method='polynomial', order=3)\n",
    "\n",
    "# Apply forward-fill (ffill) and backward-fill (bfill) to handle missing values at boundaries\n",
    "df[sorted_columns] = df[sorted_columns].ffill().bfill()\n",
    "\n",
    "# Round all numeric columns to 4 decimal places\n",
    "df[sorted_columns] = df[sorted_columns].round(4)\n",
    "\n",
    "# Recreate the DataFrame with 'Date' as the first column, followed by the sorted columns\n",
    "df = df[['Date'] + sorted_columns]\n",
    "\n",
    "# Save the updated DataFrame to a new CSV file\n",
    "df.to_csv('path_to_your_csv_file/Converted_Exchange_Rate.csv', index=False)  # Update with the correct path\n",
    "\n",
    "print(\"Date conversion completed successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f00d3ae-4077-428b-8fcf-f200e0389b61",
   "metadata": {},
   "source": [
    "## **Merge**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deedb770-29dd-421d-8b16-fcce1f34f53d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the first CSV file\n",
    "df1 = pd.read_csv('/Users/shravyadsouza/PycharmProjects/NT/csv/Merged_Exchange_Rate_2023_2024.csv')\n",
    "\n",
    "# Load the second CSV file\n",
    "df2 = pd.read_csv('/Users/shravyadsouza/PycharmProjects/NT/Converted_Exchange_Rate.csv')\n",
    "\n",
    "# Append (concatenate) the two DataFrames row-wise\n",
    "df_merged = pd.concat([df1, df2], ignore_index=True)\n",
    "\n",
    "# Save the merged DataFrame to a new CSV file\n",
    "df_merged.to_csv('/Users/shravyadsouza/PycharmProjects/NT/Exchange_Rate_2013_24.csv', index=False)\n",
    "\n",
    "print(\"CSV files have been successfully merged and saved.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8556e4b-8d28-46ab-828a-d78e68f9ff27",
   "metadata": {},
   "source": [
    "## **Sort According To Date**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a216df41-9717-416b-9cd5-137c65bbb356",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the first CSV file\n",
    "df1 = pd.read_csv('path_to_your_csv_folder/Merged_Exchange_Rate_2023_2024.csv')  # Update with the correct path\n",
    "\n",
    "# Load the second CSV file\n",
    "df2 = pd.read_csv('path_to_your_csv_folder/Converted_Exchange_Rate.csv')  # Update with the correct path\n",
    "\n",
    "# Append (concatenate) the two DataFrames row-wise\n",
    "df_merged = pd.concat([df1, df2], ignore_index=True)\n",
    "\n",
    "# Save the merged DataFrame to a new CSV file\n",
    "df_merged.to_csv('path_to_your_csv_folder/Exchange_Rate_2013_24.csv', index=False)  # Update with the correct path\n",
    "\n",
    "print(\"CSV files have been successfully merged and saved.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "237d6123-24b4-4986-b50b-93d1c22af96d",
   "metadata": {},
   "source": [
    "## **Filling Empty Values in the Final Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b08b8241-763a-4cbc-9d37-fe8d47552a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file\n",
    "file_path = \"path_to_your_csv_file/Exchange_Rate_Sorted_Descending.csv\"  # Update with the correct path\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Fill missing values with the median for each column\n",
    "df_filled = df.fillna(df.median(numeric_only=True)).round(4)\n",
    "\n",
    "# Save the updated CSV file with missing values filled with median\n",
    "output_file = \"path_to_your_csv_file/Exchange_Rate13-24.csv\"  # Update with the correct path\n",
    "df_filled.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"Missing values have been filled with median values and saved to {output_file}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
